{
    "central": {
      "name": "OPEN SOURCE",
      "subname": "AI"
    },
    "items": [
      {
        "name": "FineWeb",
        "subname": "HuggingFaceFW",
        "bullets": ["Cleaned and deduplicated english web data from CommonCrawl", "93.4 TBs"],
        "description": "Contains 15T-tokens of cleaned and deduplicated english web data from CommonCrawl. Curated for large-scale LLM training. Models trained on this data show superiority over models trained on other datasets like C4, Dolma, and RedPajama.\nEstimated number of rows: 45,995,362,478.\nSize of auto-converted Parquet files: 93.4 TB. Key feature: As of today, the largest publicly available, high-quality web dataset.",
        "icon": "https://drive.google.com/file/d/14NfJZIUWspK80MKoAfLbekNcIkL4Xnjm/view?usp=drive_link",
        "url": "https://huggingface.co/datasets/HuggingFaceFW/fineweb",
        "color": "#FFD21E",
        "x": 0.0,
        "y": -0.15
      },
      {
        "name": "orca-agentinstruct-1M-v1",
        "subname": "Microsoft",
        "bullets": ["Designed to train models for instruction-following tasks", "Prompts and responses are synthetically generated by AgentInstruct"],
        "description": "Designed to train models for instruction-following tasks like text creative writing, coding or reading comprehension. Both the prompts and the responses of this dataset are synthetically generated by AgentInstruct, using only raw text content publicly avialble on the Web as seeds.\nNumber of rows: 1,046,410\nSize of auto-converted Parquet files: 2.21 GB",
        "icon": "https://drive.google.com/file/d/1m-jM0n5aA57FbmRa7RLuXJhOC-QpDpun/view?usp=drive_link",
        "url": "https://huggingface.co/datasets/microsoft/orca-agentinstruct-1M-v1",
        "color": "#5086BC",
        "x": 0.0,
        "y": -0.05
      }
    ]
  }
  