{
    "central": {
      "name": "Hugging Face",
      "subname": "Datasets"
    },
    "items": [
      {
        "name": "FineWeb",
        "subname": "HuggingFaceFW",
        "bullets": ["Cleaned and deduplicated english web data from CommonCrawl", "93.4 TBs"],
        "description": "Contains 15T-tokens of cleaned and deduplicated english web data from CommonCrawl. Curated for large-scale LLM training. Models trained on this data show superiority over models trained on other datasets like C4, Dolma, and RedPajama.\nEstimated number of rows: 45,995,362,478.\nSize of auto-converted Parquet files: 93.4 TB. Key feature: As of today, the largest publicly available, high-quality web dataset.",
        "icon": "https://drive.google.com/file/d/14NfJZIUWspK80MKoAfLbekNcIkL4Xnjm/view?usp=drive_link",
        "url": "https://huggingface.co/datasets/HuggingFaceFW/fineweb",
        "color": "#FFD21E",
        "x": 0.0,
        "y": -0.15
      },
      {
        "name": "orca-agentinstruct-1M-v1",
        "subname": "Microsoft",
        "bullets": ["Designed to train models for instruction-following tasks", "Prompts and responses are synthetically generated by AgentInstruct"],
        "description": "Designed to train models for instruction-following tasks like text creative writing, coding or reading comprehension. Both the prompts and the responses of this dataset are synthetically generated by AgentInstruct, using only raw text content publicly avialble on the Web as seeds.\nNumber of rows: 1,046,410\nSize of auto-converted Parquet files: 2.21 GB",
        "icon": "https://drive.google.com/file/d/1m-jM0n5aA57FbmRa7RLuXJhOC-QpDpun/view?usp=drive_link",
        "url": "https://huggingface.co/datasets/microsoft/orca-agentinstruct-1M-v1",
        "color": "#5086BC",
        "x": 0.0,
        "y": -0.05
      },
      {
        "name": "arXiver",
        "subname": "Neuralwork",
        "bullets": ["Curated for question-answering tasks", "Data is converted to highly readable (.mmd) format"],
        "description": "The largest open and permissible licensed text dataset, comprising over 2 trillion tokens (2,003,039,184,047 tokens). Contains a diverse set of sources such as books, newspapers, scientific articles, government and legal documents, code, and more.\nEstimated number of rows: 396,953,971\nSize of auto-converted Parquet files (First 5GB): 2.96 GB\nKey feature: Data is permissively licensed, meaning it can be used, modified, and redistributed without legal ambiguity or risk of infringement.",
        "icon": "https://drive.google.com/file/d/10OJ348DMNH3nd8yJBqyP44unwQPL-x9a/view?usp=drive_link",
        "url": "https://huggingface.co/datasets/neuralwork/arxiver",
        "color": "#2FAD3B",
        "x": 0.0,
        "y": -0.05
      },
      {
        "name": "Common Corpus",
        "subname": "PleIAs",
        "bullets": ["Permissible licensed text dataset", "Contains a diverse set of sources (books, newspapers, scientific articles)"],
        "description": "The largest open and permissible licensed text dataset, comprising over 2 trillion tokens (2,003,039,184,047 tokens). Contains a diverse set of sources such as books, newspapers, scientific articles, government and legal documents, code, and more.\nEstimated number of rows: 396,953,971\nSize of auto-converted Parquet files (First 5GB): 2.96 GB\nKey feature: Data is permissively licensed, meaning it can be used, modified, and redistributed without legal ambiguity or risk of infringement.",
        "icon": "https://drive.google.com/file/d/10OJ348DMNH3nd8yJBqyP44unwQPL-x9a/view?usp=drive_link",
        "url": "https://huggingface.co/datasets/PleIAs/common_corpus",
        "color": "#C658C6",
        "x": 0.0,
        "y": -0.05
      }
    ]
  }
  